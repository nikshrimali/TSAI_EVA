{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "colab": {
      "name": "S7.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d53066f55ab4821977bbf995bf85d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8cd738e43394028916d8f077e823c68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_569937ed4eb74386a33b8ec0a9809244",
              "IPY_MODEL_cc513cbbd3414ea4a5a08696096ab4f9"
            ]
          }
        },
        "a8cd738e43394028916d8f077e823c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "569937ed4eb74386a33b8ec0a9809244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e936d7a5d894fe7b5b06df2ecddea16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3101d83bb5f0454581b6db43dba02b5c"
          }
        },
        "cc513cbbd3414ea4a5a08696096ab4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8549515cb7b840af8dd8db5d770719d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:04, 41835097.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac7fbada38fa401ca4f34fc34bb1fa27"
          }
        },
        "7e936d7a5d894fe7b5b06df2ecddea16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3101d83bb5f0454581b6db43dba02b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8549515cb7b840af8dd8db5d770719d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac7fbada38fa401ca4f34fc34bb1fa27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbdg0z4poCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yVpodAMpoCi",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torchsummary import summary\n",
        "%matplotlib inline\n",
        "os.chdir('d:\\Python Projects\\EVA')\n",
        "# print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "d:\\Python Projects\\EVA\n"
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "from torchcode.model.model import Net\n",
        "from torchcode.model.model_test import model_testing\n",
        "from torchcode.model.model_train import model_training\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjt4e2TpoCk",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "4d53066f55ab4821977bbf995bf85d01",
            "a8cd738e43394028916d8f077e823c68",
            "569937ed4eb74386a33b8ec0a9809244",
            "cc513cbbd3414ea4a5a08696096ab4f9",
            "7e936d7a5d894fe7b5b06df2ecddea16",
            "3101d83bb5f0454581b6db43dba02b5c",
            "8549515cb7b840af8dd8db5d770719d6",
            "ac7fbada38fa401ca4f34fc34bb1fa27"
          ]
        },
        "outputId": "3fcfd2c3-854f-45ec-a2b7-349365f3a177",
        "tags": []
      },
      "source": [
        "os.chdir('d:\\Python Projects\\EVA')\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
        "                                         shuffle=False, num_workers=4)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Files already downloaded and verified\nFiles already downloaded and verified\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # train_data = trainset.data\n",
        "# # train_data = trainset.transform(train_data)\n",
        "# print(np.mean(trainset.data[0], axis = 0))\n",
        "# print(np.mean(trainset.data[0], axis = 1))\n",
        "# print(np.mean(trainset.data[0], axis = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import numpy as  np\n",
        "# train_data = trainset.data\n",
        "# test_data = testset.data\n",
        "# print(train_data.shape, test_data.shape)\n",
        "\n",
        "# # train_data = np.concatenate((train_data, test_data), axis=0)\n",
        "# print(train_data.shape)\n",
        "# print(f'Mean of dataset {np.mean(train_data)}')\n",
        "# print(f'Std dev of dataset {np.std(train_data)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-7-da65157ebc3d>, line 8)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-da65157ebc3d>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Get the mean and std dev of entire dataset\n",
        "os.chdir('d:\\Python Projects\\EVA')\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
        "                                         shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cj433rtpoCn",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daA7bADhpoCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1b82f2e7-048c-4610-bf33-e5348ff9c5ce",
        "tags": []
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # functions to show an image\n",
        "\n",
        "\n",
        "# def imshow(img):\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# # print labels\n",
        "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28OpHA_LpoCq",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 32, 32]             896\n              ReLU-2           [-1, 32, 32, 32]               0\n       BatchNorm2d-3           [-1, 32, 32, 32]              64\n           Dropout-4           [-1, 32, 32, 32]               0\n            Conv2d-5           [-1, 64, 32, 32]          18,496\n              ReLU-6           [-1, 64, 32, 32]               0\n       BatchNorm2d-7           [-1, 64, 32, 32]             128\n           Dropout-8           [-1, 64, 32, 32]               0\n         MaxPool2d-9           [-1, 64, 16, 16]               0\n           Conv2d-10           [-1, 64, 16, 16]          36,928\n             ReLU-11           [-1, 64, 16, 16]               0\n      BatchNorm2d-12           [-1, 64, 16, 16]             128\n          Dropout-13           [-1, 64, 16, 16]               0\n        MaxPool2d-14             [-1, 64, 8, 8]               0\n           Conv2d-15            [-1, 128, 8, 8]          73,856\n             ReLU-16            [-1, 128, 8, 8]               0\n      BatchNorm2d-17            [-1, 128, 8, 8]             256\n          Dropout-18            [-1, 128, 8, 8]               0\n        MaxPool2d-19            [-1, 128, 4, 4]               0\n           Conv2d-20            [-1, 128, 4, 4]           1,280\n             ReLU-21            [-1, 128, 4, 4]               0\n      BatchNorm2d-22            [-1, 128, 4, 4]             256\n          Dropout-23            [-1, 128, 4, 4]               0\n           Conv2d-24            [-1, 128, 4, 4]             256\n             ReLU-25            [-1, 128, 4, 4]               0\n      BatchNorm2d-26            [-1, 128, 4, 4]             256\n          Dropout-27            [-1, 128, 4, 4]               0\n           Conv2d-28            [-1, 128, 4, 4]         147,584\n             ReLU-29            [-1, 128, 4, 4]               0\n      BatchNorm2d-30            [-1, 128, 4, 4]             256\n          Dropout-31            [-1, 128, 4, 4]               0\n           Conv2d-32            [-1, 128, 4, 4]         147,584\n             ReLU-33            [-1, 128, 4, 4]               0\n      BatchNorm2d-34            [-1, 128, 4, 4]             256\n          Dropout-35            [-1, 128, 4, 4]               0\n           Conv2d-36            [-1, 128, 4, 4]         147,584\n             ReLU-37            [-1, 128, 4, 4]               0\n      BatchNorm2d-38            [-1, 128, 4, 4]             256\n          Dropout-39            [-1, 128, 4, 4]               0\n        AvgPool2d-40            [-1, 128, 1, 1]               0\n           Conv2d-41             [-1, 10, 1, 1]           1,290\n================================================================\nTotal params: 577,610\nTrainable params: 577,610\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 4.24\nParams size (MB): 2.20\nEstimated Total Size (MB): 6.45\n----------------------------------------------------------------\n"
        }
      ],
      "source": [
        "from torchcode.model.model import Net\n",
        "\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdw2NNCUpoCu",
        "colab_type": "text"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4xBbDROpoCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-odOrhdpoC2",
        "colab_type": "text"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "0%|          | 0/196 [00:00<?, ?it/s]EPOCHS : 0\nLoss=1.6642729043960571 Batch_id=195 Accuracy=32.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:22<00:00,  8.54it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.5224, Accuracy: 4401/10000 (44.01%)\n\nEPOCHS : 1\nLoss=1.2907480001449585 Batch_id=195 Accuracy=49.38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:23<00:00,  8.22it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.3153, Accuracy: 5186/10000 (51.86%)\n\nEPOCHS : 2\nLoss=1.2915955781936646 Batch_id=195 Accuracy=56.66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  8.14it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.1398, Accuracy: 5863/10000 (58.63%)\n\nEPOCHS : 3\nLoss=1.4018555879592896 Batch_id=195 Accuracy=61.59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:23<00:00,  8.24it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.0771, Accuracy: 6095/10000 (60.95%)\n\nEPOCHS : 4\nLoss=1.007628083229065 Batch_id=195 Accuracy=65.11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:23<00:00,  8.18it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.0287, Accuracy: 6340/10000 (63.40%)\n\nEPOCHS : 5\nLoss=1.192190408706665 Batch_id=195 Accuracy=68.04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  7.86it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 1.0081, Accuracy: 6403/10000 (64.03%)\n\nEPOCHS : 6\nLoss=0.6280206441879272 Batch_id=195 Accuracy=70.32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  7.98it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.9178, Accuracy: 6715/10000 (67.15%)\n\nEPOCHS : 7\nLoss=0.5939908623695374 Batch_id=195 Accuracy=72.42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  8.06it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.8095, Accuracy: 7112/10000 (71.12%)\n\nEPOCHS : 8\nLoss=0.8414949178695679 Batch_id=195 Accuracy=73.92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:25<00:00,  7.78it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.8092, Accuracy: 7153/10000 (71.53%)\n\nEPOCHS : 9\nLoss=0.7713841795921326 Batch_id=195 Accuracy=75.17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:26<00:00,  7.36it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.7786, Accuracy: 7298/10000 (72.98%)\n\nEPOCHS : 10\nLoss=0.5555465221405029 Batch_id=195 Accuracy=76.64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  7.93it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.7656, Accuracy: 7323/10000 (73.23%)\n\nEPOCHS : 11\nLoss=0.6348460912704468 Batch_id=195 Accuracy=77.61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:25<00:00,  7.67it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.7504, Accuracy: 7360/10000 (73.60%)\n\nEPOCHS : 12\nLoss=0.8116561770439148 Batch_id=195 Accuracy=78.61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  7.90it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.7655, Accuracy: 7348/10000 (73.48%)\n\nEPOCHS : 13\nLoss=0.5775309205055237 Batch_id=195 Accuracy=79.63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  8.10it/s]\n  0%|          | 0/196 [00:00<?, ?it/s]\nTest set: Average loss: 0.7414, Accuracy: 7471/10000 (74.71%)\n\nEPOCHS : 14\nLoss=0.5949742794036865 Batch_id=195 Accuracy=80.34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:24<00:00,  7.85it/s]\n\nTest set: Average loss: 0.7142, Accuracy: 7547/10000 (75.47%)\n\n"
        }
      ],
      "source": [
        "from torchcode.model.model_train import model_training\n",
        "train_acc = []\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "test_losses = []\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    print(f'EPOCHS : {i}')\n",
        "    model_training(model, device, trainloader, optimizer, train_acc, train_losses, l1_loss=False)\n",
        "    misclassified = model_testing(model, device, testloader, test_acc, test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nizbsvw9poC6",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images = images[0:4]\n",
        "\n",
        "# print images\n",
        "plt.imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid shape (3, 36, 138) for image data",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-4300de3ffa2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GroundTruth: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%5s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2651\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5626\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 699\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: Invalid shape (3, 36, 138) for image data"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAx4QPHVpoC8",
        "colab_type": "text"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVLjlssWpoC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = model(images.to(device))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8OTHZEApoC_",
        "colab_type": "text"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABRIDW3lpoDA",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Predicted:    cat  ship  ship plane\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TV0TXL1poDC",
        "colab_type": "text"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ4-5CESpoDD",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'net' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-5ef0030d31c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDdwPBl8poDF",
        "colab_type": "text"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDNFuDEDpoDG",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'net' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-aeb1a1e79e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    }
  ]
}