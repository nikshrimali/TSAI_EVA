{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CapStoneEnsemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6qyBcAvqa6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74db10d1-bed7-46c4-d27d-cbcbdd09a0df"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\noperable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "632QEr6x5BsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6f5dd9-efd3-47e4-d5cd-bd095d4b2b9b"
      },
      "source": [
        "## \"Installing CUDA 8\"\n",
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
        "!rm cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-8-0\n",
        "\n",
        "\n",
        "## Downgrading GCC and Pytorch\n",
        "!pip install torch==0.4.0\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential software-properties-common -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y \n",
        "!sudo apt-get update\n",
        "!sudo apt-get install gcc-5 g++-5 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 50 --slave /usr/bin/g++ g++ /usr/bin/g++-5 \n",
        "!sudo apt-get install gcc-5 g++-5 g++-5-multilib gfortran-5\n",
        "!sudo update-alternatives --config gcc\n",
        "\n",
        "!sudo apt-get update --fix-missing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'dpkg' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt-key' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "ERROR: Could not find a version that satisfies the requirement torch==0.4.0 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 1.7.0)\n",
            "ERROR: No matching distribution found for torch==0.4.0\n",
            "WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
            "You should consider upgrading via the 'D:\\Python\\envs\\pytorch\\python.exe -m pip install --upgrade pip' command.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp5U2aF7W8l5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ef1aea-e358-4c3c-91c1-7b47be6e64c6"
      },
      "source": [
        "!git clone https://github.com/NVlabs/planercnn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'planercnn'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Total 150 (delta 0), reused 0 (delta 0), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (150/150), 1.33 MiB | 24.68 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTgOFGFOXiES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0CU0BIzPguy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bda94bd-c03b-40bb-845a-947325f1c543"
      },
      "source": [
        "%cd planercnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/planercnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1KWXXaAXLWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74138b94-9f51-424e-a3ae-fbec8421ee4a"
      },
      "source": [
        "## Building NMS\n",
        "%cd nms/src/cuda\n",
        "!nvcc -c -o nms_kernel.cu.o nms_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_60\n",
        "%cd ../..\n",
        "!python build.py\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/planercnn/nms/src/cuda\n",
            "/content/planercnn/nms\n",
            "Including CUDA code.\n",
            "/content/planercnn/nms\n",
            "generating /tmp/tmpdy6unbb5/_nms.c\n",
            "setting the current directory to '/tmp/tmpdy6unbb5'\n",
            "running build_ext\n",
            "building '_nms' extension\n",
            "creating content\n",
            "creating content/planercnn\n",
            "creating content/planercnn/nms\n",
            "creating content/planercnn/nms/src\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c _nms.c -o ./_nms.o\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/planercnn/nms/src/nms.c -o ./content/planercnn/nms/src/nms.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/nms/src/nms.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcpu_nms\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms.c:7:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KTHLongTensor_isContiguous\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     THArgCheck(THLongTensor_isContiguous(\u001b[01;35m\u001b[Kb\u001b[m\u001b[Koxes), 2, \"boxes must be contiguous\");\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:100:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTHArgCheck\u001b[m\u001b[K’\n",
            "   _THArgCheck(__FILE__, __LINE__, \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K);                       \\\n",
            "                                   \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THTensor.h:8:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THLongTensor * {aka const struct THLongTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,Real,Tensor_,NAME)\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THTensor.h:8:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,Real,Tensor_,NAME)\n",
            "                           \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/generic/THTensor.h:114:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHTensor_\u001b[m\u001b[K’\n",
            " TH_API int \u001b[01;36m\u001b[KTHTensor_\u001b[m\u001b[K(isContiguous)(const THTensor *self);\n",
            "            \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms.c:9:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KTHLongTensor_isContiguous\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     THArgCheck(THLongTensor_isContiguous(\u001b[01;35m\u001b[Ka\u001b[m\u001b[Kreas), 4, \"areas must be contiguous\");\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:100:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTHArgCheck\u001b[m\u001b[K’\n",
            "   _THArgCheck(__FILE__, __LINE__, \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K);                       \\\n",
            "                                   \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THTensor.h:8:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THLongTensor * {aka const struct THLongTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,Real,Tensor_,NAME)\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THTensor.h:8:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,Real,Tensor_,NAME)\n",
            "                           \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/generic/THTensor.h:114:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHTensor_\u001b[m\u001b[K’\n",
            " TH_API int \u001b[01;36m\u001b[KTHTensor_\u001b[m\u001b[K(isContiguous)(const THTensor *self);\n",
            "            \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/planercnn/nms/src/nms_cuda.c -o ./content/planercnn/nms/src/nms_cuda.o\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgpu_nms\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms_cuda.c:29:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kinitialization from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "   unsigned long long* mask_flat = \u001b[01;35m\u001b[KTHCudaLongTensor_data\u001b[m\u001b[K(state, mask);\n",
            "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms_cuda.c:37:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kinitialization from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "   unsigned long long * mask_cpu_flat = \u001b[01;35m\u001b[KTHLongTensor_data\u001b[m\u001b[K(mask_cpu);\n",
            "                                        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms_cuda.c:40:39:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kinitialization from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "   unsigned long long* remv_cpu_flat = \u001b[01;35m\u001b[KTHLongTensor_data\u001b[m\u001b[K(remv_cpu);\n",
            "                                       \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/nms/src/nms_cuda.c:23:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kboxes_dim\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "   int \u001b[01;35m\u001b[Kboxes_dim\u001b[m\u001b[K = THCudaTensor_size(state, boxes, 1);\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 ./_nms.o ./content/planercnn/nms/src/nms.o ./content/planercnn/nms/src/nms_cuda.o /content/planercnn/nms/src/cuda/nms_kernel.cu.o -o ./_nms.so\n",
            "/content/planercnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0jlyaWE5jgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3925a43a-68a3-45cb-dc6e-84fe58074768"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34manchors\u001b[0m/      \u001b[01;32mevaluate_utils.py\u001b[0m*  options.py         \u001b[01;32mtrain_planercnn.py\u001b[0m*\n",
            "\u001b[01;32mconfig.py\u001b[0m*    \u001b[01;34mexample_images\u001b[0m/     \u001b[01;32mplane_utils.py\u001b[0m*    \u001b[01;32mutils.py\u001b[0m*\n",
            "\u001b[01;34mdata_prep\u001b[0m/    LICENSE.md          README.md          \u001b[01;32mvisualize_utils.py\u001b[0m*\n",
            "\u001b[01;34mdatasets\u001b[0m/     \u001b[01;34mmodels\u001b[0m/             \u001b[01;32mrequirements.txt\u001b[0m*\n",
            "\u001b[01;32mevaluate.py\u001b[0m*  \u001b[01;34mnms\u001b[0m/                \u001b[01;34mroialign\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XokHnGvyRfIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac54dc7-2f59-45da-d6ce-cbd127842439"
      },
      "source": [
        "# Buliding ROI Align\n",
        "%cd /content/planercnn/roialign/roi_align/src/cuda/\n",
        "!nvcc -c -o crop_and_resize_kernel.cu.o crop_and_resize_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_60\n",
        "%cd ../../\n",
        "!python build.py\n",
        "%cd ../../\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/planercnn/roialign/roi_align/src/cuda\n",
            "/content/planercnn/roialign/roi_align\n",
            "Including CUDA code.\n",
            "/content/planercnn/roialign/roi_align\n",
            "generating /tmp/tmpoxp0_0ym/_crop_and_resize.c\n",
            "setting the current directory to '/tmp/tmpoxp0_0ym'\n",
            "running build_ext\n",
            "building '_crop_and_resize' extension\n",
            "creating content\n",
            "creating content/planercnn\n",
            "creating content/planercnn/roialign\n",
            "creating content/planercnn/roialign/roi_align\n",
            "creating content/planercnn/roialign/roi_align/src\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c _crop_and_resize.c -o ./_crop_and_resize.o -fopenmp -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/planercnn/roialign/roi_align/src/crop_and_resize.c -o ./content/planercnn/roialign/roi_align/src/crop_and_resize.o -fopenmp -std=c99\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcrop_and_resize_forward\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:134:53:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int batch_size = THCudaTensor_size(state, \u001b[01;35m\u001b[Kimage\u001b[m\u001b[K, 0);\n",
            "                                                     \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:135:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int depth = THCudaTensor_size(state, \u001b[01;35m\u001b[Kimage\u001b[m\u001b[K, 1);\n",
            "                                                \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:136:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int image_height = THCudaTensor_size(state, \u001b[01;35m\u001b[Kimage\u001b[m\u001b[K, 2);\n",
            "                                                       \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:137:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int image_width = THCudaTensor_size(state, \u001b[01;35m\u001b[Kimage\u001b[m\u001b[K, 3);\n",
            "                                                      \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:139:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int num_boxes = THCudaTensor_size(state, \u001b[01;35m\u001b[Kboxes\u001b[m\u001b[K, 0);\n",
            "                                                    \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcrop_and_resize_backward\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:184:53:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int batch_size = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads_image\u001b[m\u001b[K, 0);\n",
            "                                                     \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:185:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int depth = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads_image\u001b[m\u001b[K, 1);\n",
            "                                                \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:186:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int image_height = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads_image\u001b[m\u001b[K, 2);\n",
            "                                                       \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:187:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int image_width = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads_image\u001b[m\u001b[K, 3);\n",
            "                                                      \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:189:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int num_boxes = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads\u001b[m\u001b[K, 0);\n",
            "                                                    \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:190:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int crop_height = THCudaTensor_size(state, \u001b[01;35m\u001b[Kgrads\u001b[m\u001b[K,2);\n",
            "                                                      \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:191:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 2 of ‘\u001b[01m\u001b[KTHCudaTensor_size\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     const int crop_width = THCudaTensor_size(state,\u001b[01;35m\u001b[Kgrads\u001b[m\u001b[K,3);\n",
            "                                                    \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/TH.h:4:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/planercnn/roialign/roi_align/src/crop_and_resize.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst THCudaTensor * {aka const struct THCudaTensor *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KTHFloatTensor * {aka struct THFloatTensor *}\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   TH_CONCAT_4(\u001b[01;36m\u001b[KT\u001b[m\u001b[KH,CReal,Tensor_,NAME)\n",
            "                                        \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH/THGeneral.h:144:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KTH_CONCAT_4_EXPAND\u001b[m\u001b[K’\n",
            " #define TH_CONCAT_4_EXPAND(x,y,z,w) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K ## y ## z ## w\n",
            "                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/THCTensor.h:9:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTH_CONCAT_4\u001b[m\u001b[K’\n",
            " #define THCTensor_(NAME)   \u001b[01;36m\u001b[KTH_CONCAT_4\u001b[m\u001b[K(TH,CReal,Tensor_,NAME)\n",
            "                            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC/generic/THCTensor.h:26:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTHCTensor_\u001b[m\u001b[K’\n",
            " THC_API int64_t \u001b[01;36m\u001b[KTHCTensor_\u001b[m\u001b[K(size)(THCState *state, const THCTensor *self, int dim);\n",
            "                 \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/../../lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/planercnn/roialign/roi_align/src/crop_and_resize_gpu.c -o ./content/planercnn/roialign/roi_align/src/crop_and_resize_gpu.o -fopenmp -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 ./_crop_and_resize.o ./content/planercnn/roialign/roi_align/src/crop_and_resize.o ./content/planercnn/roialign/roi_align/src/crop_and_resize_gpu.o /content/planercnn/roialign/roi_align/src/cuda/crop_and_resize_kernel.cu.o -o ./_crop_and_resize.so\n",
            "/content/planercnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOXmHmMFcD84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c98f90-11ec-46aa-e859-3dcd94048034"
      },
      "source": [
        "!pip install torch==0.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K     |████████████████████████████████| 519.5MB 34kB/s \n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 0.4.0\n",
            "    Uninstalling torch-0.4.0:\n",
            "      Successfully uninstalled torch-0.4.0\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD8jwUi9hRJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60063a8f-a20c-43bd-cade-5b531467a1ad"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt6cQooHgJ3Z"
      },
      "source": [
        "# # Copying checkpoint to the colab from drive\n",
        "# !cp '/content/gdrive/My Drive/checkpoint.zip' '/content'\n",
        "# !unzip /content/checkpoint.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v9h9H4scxXC"
      },
      "source": [
        "# ## Loading Trained Model\n",
        "# !mv \"checkpoint.zip\" \"planercnn_checkpoint.zip\"\n",
        "# !mv planercnn_checkpoint.zip checkpoint/\n",
        "# %cd checkpoint/\n",
        "# !unzip planercnn_checkpoint.zip\n",
        "# !rm planercnn_checkpoint.zip\n",
        "# %cd ..\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zIlcjnxbDph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4ed52b-e406-42bb-b6e6-973e5874db46"
      },
      "source": [
        "import os\n",
        "if os.path.exists('../content/gdrive'):\n",
        "    print('Drive already mounted')\n",
        "\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGepkOB62lP_"
      },
      "source": [
        "# !zip -r \"planercnn.zip\" \"/content/planercnn/test/\"\n",
        "# !mkdir \"/content/gdrive/My Drive/customdata/data/PlaneRCNN\"\n",
        "# !cp \"/content/planercnn/test/planercnn.zip\" \"/content/gdrive/My Drive/customdata/data/PlaneRCNN\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si-5Pb20dWim"
      },
      "source": [
        "#  Generating the plane data from custom data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvjegxjFcNPG"
      },
      "source": [
        "# # Step 1 Compile the rendoror - Should be same as compiling the ROI align\n",
        "\n",
        "# %cd data_pred/Renderer/\n",
        "# !nvcc -c -o nms_kernel.cu.o nms_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_60\n",
        "# %cd ../..\n",
        "# !python build.py\n",
        "# %cd ..\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9lw2K3WNeT"
      },
      "source": [
        "# Training the Planercnn model via renderer\n",
        "\n",
        "# !sudo apt install libglew-dev\n",
        "# !sudo apt-get install libglm-dev\n",
        "# !sudo apt-get install libgflags-dev\n",
        "\n",
        "# #\n",
        "# %cd /content/planercnn/data_prep/Renderer\n",
        "# !cmake .\n",
        "# !make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Znt7qgUg7Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4f0b8c-e322-488e-db92-863b4aab3e90"
      },
      "source": [
        "# Copying checkpoint to the colab from drive\n",
        "if os.path.exists('../content/planercnn/checkpoint/planercnn_normal_warping_refine/checkpoint.pth'):\n",
        "    print('Checkpoint path already present')\n",
        "else:\n",
        "    print('Loading the checkpoint path')\n",
        "    !mkdir /content/planercnn/checkpoint\n",
        "    %cd /content/planercnn/checkpoint\n",
        "    !cp '/content/gdrive/My Drive/checkpoint.zip' '/content/planercnn/checkpoint'\n",
        "    !unzip checkpoint.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the checkpoint path\n",
            "/content/planercnn/checkpoint\n",
            "Archive:  checkpoint.zip\n",
            "   creating: planercnn_normal_warping_refine/\n",
            "  inflating: planercnn_normal_warping_refine/checkpoint_refine.pth  \n",
            "  inflating: planercnn_normal_warping_refine/checkpoint.pth  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_uqHarohhRZ"
      },
      "source": [
        "# # Extract the metadata to root folder $ROOT_FOLDER\"\n",
        "\n",
        "# # %cd /content/\n",
        "# !unzip metadata.zip?dl=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3MOQsUzGApl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d75caa9-75a7-4db2-c7e3-5bb04446992e"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/planercnn')\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/planercnn']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3lbMbBSokKz"
      },
      "source": [
        "sys.path.remove('/content/planercnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxNEqr-Co66J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0e0b9e-353f-4336-f9ca-a63f65e06aa8"
      },
      "source": [
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvSjWXXTpKJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VHL2OHAFhml"
      },
      "source": [
        "# from importlib import reload  \n",
        "# reload(planercnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgyQDrwt12x6"
      },
      "source": [
        "# !python planercnn/train_planercnn.py --restore=2 --suffix=warping_refine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmFixLBJnFes"
      },
      "source": [
        "# cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AmcBBUUtc5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf30420b-c7a3-4506-f4c1-7c3e8ab96c9e"
      },
      "source": [
        "%cd /content/planercnn/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/planercnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaCvL2mB2N-w"
      },
      "source": [
        "# from planercnn.train_planercnn import *\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "from models.model import *\n",
        "from models.refinement_net import *\n",
        "from models.modules import *\n",
        "from datasets.plane_stereo_dataset import *\n",
        "\n",
        "from utils import *\n",
        "from visualize_utils import *\n",
        "from evaluate_utils import *\n",
        "from options import parse_args\n",
        "from config import PlaneConfig\n",
        "\n",
        "from argparse import Namespace\n",
        "\n",
        "def rand_func(**kwargs):\n",
        "    # print('Received kwargs', kwargs)\n",
        "    args = Namespace(LR=1e-05,\n",
        "        MaskRCNNPath='../mask_rcnn_coco.pth',\n",
        "        anchorFolder='anchors/',\n",
        "        anchorType='normal',\n",
        "        batchSize=16, blocks='', checkpoint_dir='checkpoint/planercnn_normal_warping_refine',\n",
        "        considerPartial=False, convType='2', cornerLocationNoise=0.0, cornerPositiveWeight=0,\n",
        "        correctionType='one', customDataFolder='test/custom', dataFolder='../../Data/ScanNet/',\n",
        "        dataset='', debug=False, distanceThreshold2D=20, distanceThreshold3D=0.2, frameGap=20,\n",
        "        gpu=1, heatmapThreshold=0.5, height=512, keyname='planercnn_normal_warping_refine',\n",
        "        locationNoise=0.0, losses='', maskHeight=56, maskWeight=1, maskWidth=56, methods='b',\n",
        "        minNumPointRatio=0.05, modelType='', numAnchorPlanes=0, numEpochs=1000, numInputChannels=4,\n",
        "        numNodes=10, numPositiveExamples=200, numTestingImages=100, numTrainingImages=1000,\n",
        "        numViews=0, occlusionNoise=0, outputDim=256, planeAreaThreshold=500, planeWidthThreshold=10,\n",
        "        positiveWeight=0.33, predictAdjacency=False, restore=2, savePoints=False, scaleMode='variant',\n",
        "        startEpoch=-1, suffix='warping_refine', task='train', test_dir='test/planercnn_normal_warping_refine',\n",
        "        testingDataset='', testingIndex=-1, trainingMode='all', visualizeMode='', warpingWeight=0.1, width=640\n",
        "        )\n",
        "\n",
        "    config = PlaneConfig(args)\n",
        "    model = MaskRCNN(config)\n",
        "    model.load_state_dict(torch.load('/content/planercnn/checkpoint/planercnn_normal_warping_refine/checkpoint.pth'))\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJSAFRVH4Mcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64846de-6abb-45ae-c298-53e8dbe47558"
      },
      "source": [
        "model = rand_func()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/planercnn/models/model.py:1473: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dINHsrU_7MGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c99db3-43f7-4141-c530-b40887fcc673"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MaskRCNN(\n",
            "  (fpn): FPN(\n",
            "    (C1): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): SamePad2d\n",
            "      (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (C2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (C3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (C4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (C5): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (padding2): SamePad2d\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (P6): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (P5_conv1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (P5_conv2): Sequential(\n",
            "      (0): SamePad2d\n",
            "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (P4_conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (P4_conv2): Sequential(\n",
            "      (0): SamePad2d\n",
            "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (P3_conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (P3_conv2): Sequential(\n",
            "      (0): SamePad2d\n",
            "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (P2_conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (P2_conv2): Sequential(\n",
            "      (0): SamePad2d\n",
            "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (rpn): RPN(\n",
            "    (padding): SamePad2d\n",
            "    (conv_shared): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (relu): ReLU(inplace)\n",
            "    (conv_class): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): Softmax()\n",
            "    (conv_bbox): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (coordinates): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (classifier): Classifier(\n",
            "    (conv1): Conv2d(320, 1024, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (bn1): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (bn2): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace)\n",
            "    (linear_class): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    (softmax): Softmax()\n",
            "    (linear_bbox): Linear(in_features=1024, out_features=32, bias=True)\n",
            "    (linear_parameters): Linear(in_features=1024, out_features=24, bias=True)\n",
            "  )\n",
            "  (mask): Mask(\n",
            "    (padding): SamePad2d\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (bn2): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (bn4): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv5): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (sigmoid): Sigmoid()\n",
            "    (relu): ReLU(inplace)\n",
            "  )\n",
            "  (depth): Depth(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "    )\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "    )\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "    )\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "    )\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "    )\n",
            "    (deconv1): Sequential(\n",
            "      (0): Upsample(scale_factor=2, mode=nearest)\n",
            "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace)\n",
            "    )\n",
            "    (deconv2): Sequential(\n",
            "      (0): Upsample(scale_factor=2, mode=nearest)\n",
            "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace)\n",
            "    )\n",
            "    (deconv3): Sequential(\n",
            "      (0): Upsample(scale_factor=2, mode=nearest)\n",
            "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace)\n",
            "    )\n",
            "    (deconv4): Sequential(\n",
            "      (0): Upsample(scale_factor=2, mode=nearest)\n",
            "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace)\n",
            "    )\n",
            "    (deconv5): Sequential(\n",
            "      (0): Upsample(scale_factor=2, mode=nearest)\n",
            "      (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace)\n",
            "    )\n",
            "    (depth_pred): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8YpeFjd7c_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58EhPMQTFB_1"
      },
      "source": [
        "torch.save(model, '/content/model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfCkj3tJIEq4"
      },
      "source": [
        "# torch.load('/content/gdrive/My Drive/modelprcnn.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QwxM4f9xsZq"
      },
      "source": [
        "planer_decoder = list(model.children())[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uwBy3gG4udl"
      },
      "source": [
        "# print(list(resnet_head.children())[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWjPDa711peK"
      },
      "source": [
        "class MonDepthEst(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MonDepthEst, self).__init__()\n",
        "\n",
        "        # Adding Resnet 101 layers\n",
        "        self.planer_decoder = planer_decoder\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = planer_decoder[0](x)\n",
        "        print('1-2')\n",
        "        x = planer_decoder[1](x)\n",
        "        print('2-3')\n",
        "        x = planer_decoder[2](x)\n",
        "        print(x,'1')\n",
        "        x = planer_decoder[3](x)\n",
        "        print(x,'1')\n",
        "        out = self.planer_decoder(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtfkb6FA4A3X"
      },
      "source": [
        "only_resnet = MonDepthEst().to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2OEAxo65yGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "be875a09-1035-491d-a0ce-074548891ca6"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(only_resnet, input_size= (256,13,13))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-cc39da88a6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-fff337bacccb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaner_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaner_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2-3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaner_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 1, 1], expected input[2, 256, 13, 13] to have 3 channels, but got 256 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Soh0l952ow"
      },
      "source": [
        "# Yolo Layers - Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7wsSVoZ55nh"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/nikshrimali/YoloV3.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjxkRbz18tw9"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/YoloV3')\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wejF45I69IHB"
      },
      "source": [
        "# !rm -r \"/content/YoloV3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MDSy9NH-V3e"
      },
      "source": [
        "# Get Yolo Model from Github repo\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As88JtVc8gw7"
      },
      "source": [
        "#Load the weights from pre-trained model\n",
        "%cd /content/YoloV3\n",
        "\n",
        "from models import *\n",
        "from utils.parse_config import *\n",
        "\n",
        "def get_yolo():\n",
        "\n",
        "    path = './cfg/yolov3-custom.cfg'\n",
        "    yolo_model = Darknet(path).to(\"cuda\")\n",
        "\n",
        "    sc_yolokeys = list(yolo_model.state_dict().keys())\n",
        "    model_path = r\".\\pretrained_model\\best273.pt\"\n",
        "    ptmodel = torch.load(model_path)['model']\n",
        "    pt_yolokeys = (list(ptmodel.keys())[330:])\n",
        "    # Updating the Yolo model with Pre-trained weights\n",
        "    for i, keys in enumerate(sc_yolokeys):\n",
        "        yolo_model.state_dict()[keys] = ptmodel[pt_yolokeys[i]]\n",
        "    # Freeze the layers for training\n",
        "    for param in yolo_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    return yolo_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG67qcQH9qmQ"
      },
      "source": [
        "yolo_model = get_yolo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5R1TVsx9rUb"
      },
      "source": [
        "# Loading the pretrained encoder of Midas\n",
        "%cd /content/MiDaS\n",
        "\n",
        "\n",
        "from midas.midas_net import *\n",
        "def get_midas():\n",
        "    midas_model = MidasNet().to(\"cuda\")\n",
        "    # Freezing layers for updates\n",
        "    for param in midas_model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "    return midas_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQwkEfu9tFq"
      },
      "source": [
        "midas_model = get_midas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjCQqZF098Bc"
      },
      "source": [
        "# Emsemble model\n",
        "class MyEnsemble(nn.Module):\n",
        "    def __init__(self, midas, yolo_decoder, rcnn_decoder = nn.Module(), train_yolo=False, train_rcnn=False, train_all=True):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.midas = midas\n",
        "        self.yolo_decoder = yolo_decoder\n",
        "        self.train_yolo = train_yolo\n",
        "        self.train_rcnn = train_rcnn\n",
        "        self.train_all = train_all\n",
        "        self.rcnn_decoder = rcnn_decoder\n",
        "        # Remove last linear layer\n",
        "        # self.modelA.fc = nn.Identity()\n",
        "        # self.modelB.fc = nn.Identity()\n",
        "        \n",
        "        # Create a 3 Layer buffer between Midas Encoder and Yolo Decoder\n",
        "        # Everything would be freezed but this\n",
        "        \n",
        "        self.yolo_buffer = nn.Sequential(\n",
        "            nn.Conv2d(2048, 2048, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(2048, 2048, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(2048, 2048, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        layer_1 = self.midas.pretrained.layer1(x.clone())\n",
        "        layer_2 = self.midas.pretrained.layer2(layer_1)\n",
        "        layer_3 = self.midas.pretrained.layer3(layer_2)\n",
        "        layer_4 = self.midas.pretrained.layer4(layer_3)\n",
        "\n",
        "        # if self.train_all:\n",
        "        layer_1_rn = self.midas.scratch.layer1_rn(layer_1)\n",
        "        layer_2_rn = self.midas.scratch.layer2_rn(layer_2)\n",
        "        layer_3_rn = self.midas.scratch.layer3_rn(layer_3)\n",
        "        layer_4_rn = self.midas.scratch.layer4_rn(layer_4)\n",
        "\n",
        "        path_4 = self.midas.scratch.refinenet4(layer_4_rn)\n",
        "        path_3 = self.midas.scratch.refinenet3(path_4, layer_3_rn)\n",
        "        path_2 = self.midas.scratch.refinenet2(path_3, layer_2_rn)\n",
        "        path_1 = self.midas.scratch.refinenet1(path_2, layer_1_rn)\n",
        "\n",
        "        out = self.midas.scratch.output_conv(path_1)\n",
        "\n",
        "        # Now adding a buffer and Yolo Layers\n",
        "        yolo_buffer = self.yolo_buffer(layer_4)\n",
        "        yolo_output = self.yolo_decoder(yolo_buffer)         \n",
        "\n",
        "        # return torch.squeeze(out, dim=1), yolo_output\n",
        "        \n",
        "        # if self.train_yolo:\n",
        "        #     yolo_buffer = self.yolo_buffer(layer_4)\n",
        "        #     yolo_output = self.yolo_decoder(yolo_buffer)         \n",
        "\n",
        "        return  yolo_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6COLeUrS9-k1"
      },
      "source": [
        "model = MyEnsemble(midas_model, yolo_model).to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNLOJowv-CS6"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3,416,416))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}